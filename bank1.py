# importation des bibiotheques
import numpy as np
import pandas as pd
import matplotlib as plt
import seaborn as sns
import streamlit as st
import altair as alt 


# Configuration de la page
st.set_page_config(
    page_title="Classification des Donn√©es Bancaires",
    page_icon="üè¶",  
    layout="wide", 
    initial_sidebar_state="expanded"
)

alt.themes.enable("dark")

# -------------------------
# Barre lat√©rale

if 'page_selection' not in st.session_state:
    st.session_state.page_selection = 'a_propos'  # Page par d√©faut

# Fonction pour mettre √† jour page_selection
def set_page_selection(page):
    st.session_state.page_selection = page

with st.sidebar:
    st.title(' üè¶ Classification des Donn√©es Bancaires')

    # Navigation par boutons
    st.subheader("Sections")
    if st.button("√Ä Propos", use_container_width=True, on_click=set_page_selection, args=('a_propos',)):
        pass
    if st.button("Jeu de Donn√©es", use_container_width=True, on_click=set_page_selection, args=('jeu_de_donnees',)):
        pass
    if st.button("Analyse Exploratoire", use_container_width=True, on_click=set_page_selection, args=('analyse_exploratoire',)):
        pass
    if st.button("Pr√©diction", use_container_width=True, on_click=set_page_selection, args=('prediction',)):
        pass
    if st.button("Conclusion", use_container_width=True, on_click=set_page_selection, args=('conclusion',)):
        pass

    # D√©tails du projet
    st.subheader("R√©sum√©")
    st.markdown("""
        Un tableau de bord interactif pour explorer et classifier les donn√©es d'une campagne marketing bancaire.

        -  [Jeu de Donn√©es](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing)
        -  [Notebook Google Colab](https://colab.research.google.com/drive/1KJDBrx3akSPUW42Kbeepj64ZisHFD-NV?usp=sharing)
        -  [D√©p√¥t GitHub](https://github.com/teguegni/bank-additionnal-full/Streamlit-Bank-Classification-Dashboard)

        **Auteur :** [`Kenfack Teguegni Junior`](https://jcdiamante.com)
    """)

# -------------------------

# Charger les donn√©es
try:
    df = pd.read_csv('bank-additional-full.csv', delimiter=';')
except FileNotFoundError:
    st.error("Le fichier 'bank-additional-full.csv' est introuvable. Veuillez v√©rifier son emplacement.")
    st.stop()

# Page principale
if st.session_state.page_selection == 'a_propos':
    # Page √Ä Propos
    st.title("Ô∏è √Ä Propos")
    st.markdown("""
        Cette application explore le jeu de donn√©es **Bank Marketing** et propose :

        - Une exploration visuelle des donn√©es.
        - Un pr√©traitement et nettoyage des donn√©es.
        - La construction et l'√©valuation de mod√®les d'apprentissage automatique.
        - Une interface interactive pour pr√©dire si un client souscrira √† un produit.

        **Technologies utilis√©es :**
        - Python (Streamlit, Altair, Pandas)
        - Machine Learning (Scikit-learn)

        **Auteur : Kenfack Teguegni Junior**

        ‚úâÔ∏è Contact : kenfackteguegni@gmail.com
    """)
elif st.session_state.page_selection == 'conclusion':
     # Page √Ä Propos
    st.title("Ô∏è conclusion")
    st.markdown("""
        Un traitement minutieux et r√©fl√©chi du DataFrame bank-additional-full est fondamental pour maximiser la pr√©cision 
        et la fiabilit√© du mod√®le de pr√©diction. En combinant explorations, pr√©traitements ad√©quats, et √©valuations rigoureuses,
         on peut d√©velopper un mod√®le robuste qui est mieux √©quip√© pour pr√©dire les comportements des clients envers la souscription √† un produit.
    """)

elif st.session_state.page_selection == 'jeu_de_donnees':
    # Page Jeu de Donn√©es
    st.title(" Jeu de Donn√©es")

    # Afficher les premi√®res lignes du DataFrame
    if st.checkbox("Afficher le DataFrame"):
        nb_rows = st.slider("Nombre de lignes √† afficher :", min_value=105, max_value=41189, value=10)
        st.write(df.head(nb_rows))

    # Afficher les statistiques descriptives
    if st.checkbox("Afficher les statistiques descriptives"):
        st.write(df.describe())

elif st.session_state.page_selection == 'analyse_exploratoire':
    st.title(" Analyse Exploratoire")
    #  verifies s'il ya des duplications dans la dataframe et affiche le nombre de duplications
    duplicates = df.duplicated()
    duplicates.value_counts()
    # supprimations des duplications 
    df.drop_duplicates()
    # Remplacement des valeurs 'unknown'
    for column in df.columns:
        if df[column].dtype == 'object':
            mode_value = df[column].mode()[0]
            df[column] = df[column].replace('unknown', mode_value)
    # V√©rification des valeurs manquantes
    st.subheader("V√©rification des valeurs manquantes")
    missing_values = df.isnull().sum()
    st.write(missing_values[missing_values > 0])

    # Graphique Altair
    st.subheader("Relation entre l'√¢ge et le m√©tier")
    df['job'] = df['job'].astype('category')
    age_job_chart = (
        alt.Chart(df)
        .mark_circle(size=60)
        .encode(
            x=alt.X('age:Q', title='√Çge'),
            y=alt.Y('job:O', title='M√©tier', sort=None),
            color='y:N',
            tooltip=['age:Q', 'job:N', 'y:N']
        )
        .properties(
            title='Relation entre l\'√¢ge et le m√©tier',
            width=600,
            height=400
        )
        .interactive()
    )
    st.altair_chart(age_job_chart, use_container_width=True)

elif st.session_state.page_selection == 'apprentissage_automatique':
    # selection des colonnes numerique 
    colonne_numerique = df[['age','duration','campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']]
    print(colonne_numerique)
    # Fonction pour d√©tecter et remplacer les valeurs aberrantes avec les Bounds
    def replace_outliers(df):
        for col in df.select_dtypes(include=['number']).columns:  # Only process numeric columns
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            df[col] = np.where(df[col] < lower_bound, lower_bound, df[col])
            df[col] = np.where(df[col] > upper_bound, upper_bound,df[col])
    # V√©rifiez que les colonnes n√©cessaires existent
    print(df.columns)
    replace_outliers(df)
    sns.boxplot(x='age',data=df)
    # faire la matrice de correlation
    sns.heatmap(df.select_dtypes(include=['number']).corr(),annot =True)
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('marital').size()
    # calcul de la frequence par categories
    fe = df.groupby('marital').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'marital_freq_encode'] = df['marital'].map(fe)
    df
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('job').size()
    # calcul de la frequence par categories
    fe = df.groupby('job').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'job_freq_encode'] = df['job'].map(fe)
    df
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('education').size()
    # calcul de la frequence par categories
    fe = df.groupby('education').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'education_freq_encode'] = df['education'].map(fe)
    df
    # encodage colonne categorielle de type binaire x
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    df.default = le.fit_transform(df.default)
    df.housing = le.fit_transform(df.housing)
    df.loan = le.fit_transform(df.loan)
    df.contact = le.fit_transform(df.contact)
    df.head()
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('month').size()
    # calcul de la frequence par categories
    fe = df.groupby('month').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'month_freq_encode'] = df['month'].map(fe)
    df
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('day_of_week').size()
    # calcul de la frequence par categories
    fe = df.groupby('day_of_week').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'day_freq_encode'] = df['day_of_week'].map(fe)
    df
    # encodage categorielle avec plusieurs valeurs differentes pour les features 
    # grouper les categories 
    df.groupby('poutcome').size()
    # calcul de la frequence par categories
    fe = df.groupby('poutcome').size()/len(df)
    # insertion dans le dataframe
    df.loc[:,'poutcome_freq_encode'] = df['poutcome'].map(fe)
    df
    from sklearn.preprocessing import LabelEncoder  
    # Cr√©ation de l'encodeur  
    encoder = LabelEncoder()  
    df['y_encoded'] = encoder.fit_transform(df['y'])  
    # Suppression de plusieurs colonnes  
    colonnes_a_supprimer = ['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome','y']  
    df_propre = df.drop(colonnes_a_supprimer, axis=1)  

    # Afficher le DataFrame r√©sultant  
    df_propre  
    from imblearn.over_sampling import RandomOverSampler  
    y_encoded = df_propre['y_encoded'].values  # Remplacez 'target' par le nom de votre colonne cible dans df_propre si n√©cessaire  

    # D√©finir le sur√©chantillonneur  
    ros = RandomOverSampler(random_state=42)  

    # Cr√©er une matrice X factice (ou utilisez vos features r√©elles √† partir de df_propre)  
    X = df_propre.drop(columns=['y_encoded']).values  # Assurez-vous de retirer la colonne cible  

    # Appliquer le sur√©chantillonnage  
    X_resampled, y_resampled = ros.fit_resample(X, y_encoded)  

    # Convertir les r√©sultats en DataFrame pour une manipulation plus facile si n√©cessaire  
    df_resampled = pd.DataFrame(X_resampled, columns=df_propre.columns[:-1])  # Retirez la derni√®re colonne correspondant √† 'target'  
    df_resampled['y_encoded'] = y_resampled  # Ajoutez la colonne cible √©quilibr√©e  

    # Afficher les r√©sultats  
    print("Distribution originale :")  
    print(pd.Series(y_encoded).value_counts())  
    print("\nDistribution apr√®s sur√©chantillonnage :")  
    print(pd.Series(y_resampled).value_counts())  
    from sklearn.model_selection import train_test_split
    from sklearn.ensemble import RandomForestClassifier
    # definition des donnees d'entrainement et de la variable cible
    X = df_propre[['age', 'duration', 'campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed','marital_freq_encode','job_freq_encode','education_freq_encode','month_freq_encode','day_freq_encode','poutcome_freq_encode']]
    y = df_propre['y_encoded']  
    # Diviser les donn√©es en ensembles d'entra√Ænement et de test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Entra√Æner un mod√®le simple pour tester
    model = RandomForestClassifier()
    model.fit(X_train, y_train)
    from sklearn.metrics import accuracy_score, classification_report 
    # Faire des pr√©dictions sur l'ensemble de test  
    y_pred = model.predict(X_test)  

    # √âvaluer le mod√®le  
    accuracy = accuracy_score(y_test, y_pred)  
    report = classification_report(y_test, y_pred)  

    # Afficher les r√©sultats  
    print(f'Accuracy: {accuracy:.2f}')  
    print('Classification Report:')  
    print(report)   
elif st.session_state.page_selection == 'prediction':
        # ... (votre code pour la page de pr√©diction)
        # Page Pr√©diction  
    st.title("üîÆ Pr√©diction")  
    from sklearn.ensemble import RandomForestClassifier  
    import streamlit as st  

    # Formulaire pour saisir les caract√©ristiques  
    age = st.number_input("√Çge du client", min_value=18, max_value=120, value=30)  
    duration = st.number_input("Dur√©e du contact (seconds)", min_value=0, value=60)  
    campaign = st.number_input("Nombre de contacts lors de la campagne", min_value=1, value=1)  
    pdays = st.number_input("Nombre de jours depuis le dernier contact", min_value=-1, value=-1)  # -1 si jamais contact√©  
    previous = st.number_input("Nombre de contacts avant cette campagne", min_value=0, value=0)  
    emp_var_rate = st.number_input("Taux de variation de l'emploi (%)", value=0.0)  
    cons_price_idx = st.number_input("Indice des prix √† la consommation", value=93.0)  
    cons_conf_idx = st.number_input("Indice de confiance des consommateurs", value=-40.0)  
    euribor3m = st.number_input("Taux Euribor √† 3 mois (%)", value=0.0)  
    nr_employed = st.number_input("Nombre d'employ√©s (calcul√©)", value=5191)  

    # Variables cat√©gorielles (encod√©es)  
    marital_freq_encode = st.selectbox("Statut marital", ["c√©libataire", "mari√©", "divorc√©"])  
    job_freq_encode = st.selectbox("Profession", ["ouvrier", "employ√©", "professionnel", "autre"])  
    education_freq_encode = st.selectbox("Niveau d'√©ducation", ["primaire", "secondaire", "tertiaire", "autre"])  
    month_freq_encode = st.selectbox("Mois de contact", ["janvier", "f√©vrier", "mars", "avril", "mai", "juin", "juillet", "ao√ªt", "septembre", "octobre", "novembre", "d√©cembre"])  
    day_freq_encode = st.selectbox("Jour de contact", list(range(1, 32)))  
    poutcome_freq_encode = st.selectbox("R√©sultat de la campagne pr√©c√©dente", ["succ√®s", "√©chec", "autre"])  

    # Vous pouvez √©galement ajouter un bouton pour soumettre le formulaire  
if st.button('Soumettre'):  
    # Traitement des donn√©es ou affichage des r√©sultats ici  
    st.write("Donn√©es soumises avec succ√®s!")
    
   
