import numpy as np
import pandas as pd
# import matplotlib.pyplot as plt # Non utilis√© directement dans ce code, peut √™tre enlev√© si inutile ailleurs
# import seaborn as sns # Non utilis√© directement dans ce code, peut √™tre enlev√© si inutile ailleurs
import streamlit as st
import altair as alt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
import pickle
import base64 # Utile pour une alternative d'encodage si l'URL pose probl√®me

# --- Configuration de la page ---
st.set_page_config(
    page_title="Classification des Donn√©es Bancaires",
    page_icon="üè¶",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- Fonction pour ajouter l'arri√®re-plan ---
def add_bg_from_url(url):
    """Ajoute une image d'arri√®re-plan √† partir d'une URL."""
    st.markdown(
         f"""
         <style>
         .stApp {{
             background-image: url("{url}");
             background-attachment: fixed;
             background-size: cover;
             background-repeat: no-repeat;
         }}
         /* Ajout d'un peu de transparence aux √©l√©ments principaux pour mieux voir le fond */
         /* [data-testid="stSidebar"], [data-testid="stHeader"], .main .block-container {{
             background-color: rgba(255, 255, 255, 0.8); /* Blanc avec 80% opacit√© */
             /* Vous pouvez ajuster la couleur et l'opacit√© */
         /* }} */
         /* Optionnel: Style pour rendre le texte plus lisible sur l'image */
         /* body, .stMarkdown, .stButton > button, .stTextInput > div > div > input, .stNumberInput > div > div > input {{
             color: #FFFFFF; /* Texte blanc */
             /* text-shadow: 1px 1px 2px black; /* Ombre port√©e pour lisibilit√© */
         /* }} */

         </style>
         """,
         unsafe_allow_html=True
     )

# --- URL de l'image brute sur GitHub ---
image_url = "https://raw.githubusercontent.com/teguegni/bank-additionnal-full/main/image1.jpg"
add_bg_from_url(image_url)


# --- Th√®me Altair ---
# alt.themes.enable("dark") # Peut entrer en conflit avec un fond clair, √† ajuster si besoin

# --- Barre lat√©rale ---
if 'page_selection' not in st.session_state:
    st.session_state.page_selection = 'a_propos'  # Page par d√©faut

# Fonction pour mettre √† jour page_selection
def set_page_selection(page):
    st.session_state.page_selection = page

with st.sidebar:
    st.title('üè¶ Classification Donn√©es Bancaires')
    # Navigation par boutons
    st.subheader("Sections")
    st.button("√Ä Propos", use_container_width=True, on_click=set_page_selection, args=('a_propos',), key="btn_a_propos")
    st.button("Jeu de Donn√©es", use_container_width=True, on_click=set_page_selection, args=('jeu_de_donnees',), key="btn_jeu_de_donnees")
    st.button("Analyse Exploratoire", use_container_width=True, on_click=set_page_selection, args=('analyse_exploratoire',), key="btn_analyse_exploratoire")
    # Correction: Ajout du bouton pour la section 'apprentissage_automatique' si elle existe
    st.button("Apprentissage Automatique", use_container_width=True, on_click=set_page_selection, args=('apprentissage_automatique',), key="btn_apprentissage")
    st.button("Pr√©diction", use_container_width=True, on_click=set_page_selection, args=('prediction',), key="btn_prediction")
    st.button("Conclusion", use_container_width=True, on_click=set_page_selection, args=('conclusion',), key="btn_conclusion")

    # D√©tails du projet
    st.subheader("R√©sum√©")
    st.markdown("""
        Un tableau de bord interactif pour explorer et classifier les donn√©es d'une campagne marketing bancaire.
        - [Jeu de Donn√©es](URL_VERS_VOTRE_JEU_DE_DONNEES) - [Notebook Google Colab](URL_VERS_VOTRE_NOTEBOOK) - [D√©p√¥t GitHub](https://github.com/teguegni/bank-additionnal-full) Auteur : Kenfack Teguegni Junior
    """)

# --- Chargement des donn√©es ---
# Utiliser un chemin relatif ou absolu correct, ou s'assurer que le fichier est dans le m√™me dossier
DATA_URL = 'bank-additional-full.csv'
try:
    df_original = pd.read_csv(DATA_URL, delimiter=';')
    # Cr√©er une copie pour les manipulations afin de ne pas modifier l'original √† chaque rechargement
    df = df_original.copy()
except FileNotFoundError:
    st.error(f"Le fichier '{DATA_URL}' est introuvable. Assurez-vous qu'il se trouve dans le bon r√©pertoire.")
    # Essayer de charger depuis l'URL brute du d√©p√¥t GitHub comme alternative
    try:
        st.warning("Tentative de chargement du fichier depuis GitHub...")
        github_data_url = "https://raw.githubusercontent.com/teguegni/bank-additionnal-full/main/bank-additional-full.csv"
        df_original = pd.read_csv(github_data_url, delimiter=';')
        df = df_original.copy()
        st.success("Chargement depuis GitHub r√©ussi.")
    except Exception as e:
        st.error(f"√âchec du chargement depuis GitHub √©galement. Erreur : {e}")
        st.stop() # Arr√™ter l'ex√©cution si les donn√©es ne peuvent pas √™tre charg√©es


# --- Fonction principale et logique des pages ---
def main():
    # Page principale
    if st.session_state.page_selection == 'a_propos':
        st.title("Ô∏è √Ä Propos")
        st.markdown("""
            Cette application explore le jeu de donn√©es Bank Marketing et propose :
            - Une exploration visuelle des donn√©es.
            - Un pr√©traitement et nettoyage des donn√©es.
            - La construction et l'√©valuation de mod√®les d'apprentissage automatique.
            - Une interface interactive pour pr√©dire si un client souscrira √† un produit.

            **Technologies utilis√©es :**
            - Python (Streamlit, Altair, Pandas, Scikit-learn)
            - Machine Learning (Random Forest)

            **Auteur :** Kenfack Teguegni Junior
            ‚úâÔ∏è **Contact :** kenfackteguegni@gmail.com
            """)

    elif st.session_state.page_selection == 'conclusion':
        st.title("Ô∏è Conclusion")
        st.markdown("""
            Un traitement minutieux et r√©fl√©chi du DataFrame `bank-additional-full.csv` est fondamental pour maximiser la pr√©cision
            et la fiabilit√© du mod√®le de pr√©diction. En combinant explorations, pr√©traitements ad√©quats (gestion des 'unknown', encodage, traitement des outliers, r√©√©quilibrage), et √©valuations rigoureuses,
            un mod√®le robuste peut √™tre d√©velopp√© pour mieux pr√©dire les comportements des clients envers la souscription √† un produit.

            Ce tableau de bord Streamlit fournit une interface interactive pour visualiser les donn√©es, comprendre les √©tapes de pr√©traitement, et tester le mod√®le de pr√©diction final.
            """)

    elif st.session_state.page_selection == 'jeu_de_donnees':
        st.title(" Jeu de Donn√©es")
        st.markdown("Aper√ßu du jeu de donn√©es brut charg√©.")
        # Afficher les premi√®res lignes du DataFrame original
        if st.checkbox("Afficher le DataFrame brut", key="chk_afficher_df_brut", value=True):
            nb_rows = st.slider("Nombre de lignes √† afficher :", min_value=5, max_value=50, value=10, key="slider_nb_rows_brut")
            st.dataframe(df_original.head(nb_rows)) # Utiliser df_original ici

        st.markdown("---")
        st.markdown("Informations sur le DataFrame :")
        st.write(f"Nombre de lignes : {df_original.shape[0]}")
        st.write(f"Nombre de colonnes : {df_original.shape[1]}")

        # Afficher les statistiques descriptives
        if st.checkbox("Afficher les statistiques descriptives (Num√©riques)", key="chk_stats_desc_num"):
            st.write(df_original.describe(include=np.number))
        if st.checkbox("Afficher les statistiques descriptives (Cat√©gorielles)", key="chk_stats_desc_cat"):
             st.write(df_original.describe(include='object'))


    elif st.session_state.page_selection == 'analyse_exploratoire':
        st.title(" Analyse Exploratoire et Pr√©traitement")

        # Utiliser la copie df pour les modifications
        df_processed = df.copy()

        st.subheader("1. Gestion des Duplications")
        duplicates_before = df_processed.duplicated().sum()
        st.write(f"Nombre de lignes dupliqu√©es avant suppression : {duplicates_before}")
        if duplicates_before > 0:
            df_processed = df_processed.drop_duplicates()
            st.write(f"Nombre de lignes apr√®s suppression des duplications : {df_processed.shape[0]}")
        else:
            st.write("Aucune ligne dupliqu√©e trouv√©e.")

        st.subheader("2. Gestion des Valeurs 'unknown'")
        st.write("Remplacement des valeurs 'unknown' par le mode (valeur la plus fr√©quente) de chaque colonne cat√©gorielle.")
        unknown_counts = {}
        for column in df_processed.select_dtypes(include='object').columns:
            if 'unknown' in df_processed[column].unique():
                unknown_counts[column] = df_processed[column].value_counts().get('unknown', 0)
                mode_value = df_processed[column].mode()[0]
                if mode_value == 'unknown': # Si le mode lui-m√™me est 'unknown', choisir le second mode si possible
                   modes = df_processed[column].mode()
                   if len(modes) > 1:
                       mode_value = modes[1]
                   else: # Cas tr√®s improbable o√π 'unknown' est la seule valeur
                       st.warning(f"La seule valeur dans '{column}' est 'unknown'. Impossible de remplacer.")
                       continue # Passer √† la colonne suivante
                df_processed[column] = df_processed[column].replace('unknown', mode_value)
        if unknown_counts:
             st.write("Nombre de valeurs 'unknown' remplac√©es par colonne :")
             st.write(unknown_counts)
        else:
             st.write("Aucune valeur 'unknown' trouv√©e dans les colonnes objectives.")


        st.subheader("3. V√©rification des Valeurs Manquantes (apr√®s remplacement des 'unknown')")
        missing_values = df_processed.isnull().sum()
        missing_data = missing_values[missing_values > 0]
        if not missing_data.empty:
            st.write("Colonnes avec des valeurs manquantes restantes :")
            st.write(missing_data)
            # Ici, vous pourriez ajouter une strat√©gie pour imputer ces valeurs si n√©cessaire
        else:
            st.write("Aucune valeur manquante (null) d√©tect√©e apr√®s le traitement des 'unknown'.")


        st.subheader("4. Visualisation Exploratoire")
        st.write("Relation entre l'√¢ge, le m√©tier et la souscription (variable cible 'y').")

        # S'assurer que 'job' est de type object ou category pour le graphique
        df_processed['job'] = df_processed['job'].astype('category')

        # Utiliser une copie pour √©viter les avertissements de modification
        df_chart = df_processed.copy()
        df_chart['Souscription'] = df_chart['y'].map({'yes': 'Oui', 'no': 'Non'}) # Rendre la l√©gende plus claire


        age_job_chart = (
            alt.Chart(df_chart)
            .mark_circle(size=60, opacity=0.7) # Ajout d'opacit√© pour les points superpos√©s
            .encode(
                x=alt.X('age', title='√Çge'),
                y=alt.Y('job', title='M√©tier', sort='-x'), # Trier les m√©tiers par exemple
                color=alt.Color('Souscription', title='Souscrit ?', scale=alt.Scale(scheme='category10')), # Utiliser la colonne renomm√©e
                tooltip=[
                    alt.Tooltip('age', title='√Çge'),
                    alt.Tooltip('job', title='M√©tier'),
                    alt.Tooltip('Souscription', title='Souscrit ?')
                    ]
            )
            .properties(
                title="Relation √Çge / M√©tier color√©e par la Souscription",
                # width=700, # Laisser Streamlit g√©rer la largeur avec use_container_width
                height=500
            )
            .interactive() # Permet le zoom et le d√©placement
        )
        st.altair_chart(age_job_chart, use_container_width=True)

        # Sauvegarder l'√©tat trait√© pour la page suivante si n√©cessaire
        # st.session_state.df_processed = df_processed # D√©commenter si besoin


    elif st.session_state.page_selection == 'apprentissage_automatique':
    st.title("‚öôÔ∏è Apprentissage Automatique")
    df_ml = df_original.copy()

    # 1. Liste des colonnes √† encoder
    categorical_cols_freq = ['marital', 'job', 'education', 'month', 'day_of_week', 'poutcome']  # D√©finition explicite

    # 2. Encodage par fr√©quence
    st.subheader("Encodage des Variables Cat√©gorielles")
    df_encoded = df_ml.copy()
    for column in categorical_cols_freq:  # Pas d'erreur ici
        fe = df_encoded.groupby(column).size() / len(df_encoded)
        df_encoded[f'{column}_freq_encode'] = df_encoded[column].map(fe)

    # 3. Encodage Label pour les autres colonnes
    categorical_cols_label = ['contact', 'housing', 'loan', 'default', 'y']
    label_encoder = LabelEncoder()
    for column in categorical_cols_label:
        df_encoded[column] = label_encoder.fit_transform(df_encoded[column])

    # ... (suite du code)

        # Encodage de la colonne cible 'y'
        st.write("Encodage Label (0/1) pour la variable cible 'y' ('no'=0, 'yes'=1)")
        encoder_y = LabelEncoder()
        # S'assurer que 'y' existe avant d'encoder
        if 'y' in df_encoded.columns:
            df_encoded['y_encoded'] = encoder_y.fit_transform(df_encoded['y'])
            target_mapping = dict(zip(encoder_y.classes_, encoder_y.transform(encoder_y.classes_)))
            st.write(f"Mapping de la cible : {target_mapping}")
        else:
            st.error("La colonne cible 'y' est manquante.")
            st.stop()

        # Suppression des colonnes cat√©gorielles originales et de 'y'
        cols_to_drop = categorical_cols_freq + categorical_cols_label + ['y']
        # V√©rifier que les colonnes √† supprimer existent bien
        cols_to_drop_existing = [col for col in cols_to_drop if col in df_encoded.columns]
        df_final = df_encoded.drop(columns=cols_to_drop_existing)

        st.subheader("Pr√©paration Finale des Donn√©es")
        st.write("Dimensions du DataFrame pr√™t pour le mod√®le : ", df_final.shape)
        if st.checkbox("Afficher les premi√®res lignes des donn√©es encod√©es", key="chk_df_final"):
             st.dataframe(df_final.head())


        st.subheader("Gestion du D√©s√©quilibre des Classes")
        target_counts = df_final['y_encoded'].value_counts(normalize=True)
        st.write("Distribution de la classe cible avant r√©√©quilibrage :")
        st.write(target_counts)

        if st.checkbox("Activer le sur√©chantillonnage (Upsampling) de la classe minoritaire", key="cb_upsampling", value=True):
             st.write("Application du sur√©chantillonnage pour √©quilibrer les classes...")
             df_majority = df_final[df_final.y_encoded == 0]
             df_minority = df_final[df_final.y_encoded == 1]

             if len(df_minority) == 0 or len(df_majority) == 0:
                 st.error("Impossible de sur√©chantillonner : une des classes est vide.")
                 st.stop()

             df_minority_upsampled = resample(df_minority,
                                              replace=True,     # √©chantillonnage avec remplacement
                                              n_samples=len(df_majority), # pour correspondre √† la classe majoritaire
                                              random_state=42) # pour la reproductibilit√©

             df_upsampled = pd.concat([df_majority, df_minority_upsampled])
             st.write("Distribution de la classe cible apr√®s sur√©chantillonnage :")
             st.write(df_upsampled['y_encoded'].value_counts(normalize=True))
             data_ready = df_upsampled
        else:
             st.write("Entra√Ænement sur les donn√©es d√©s√©quilibr√©es.")
             data_ready = df_final


        st.subheader("Division Entra√Ænement / Test")
        X = data_ready.drop(columns=['y_encoded']).values
        y = data_ready['y_encoded'].values
        test_size = st.slider("Pourcentage pour l'ensemble de test", 0.1, 0.5, 0.2, 0.05, key="slider_test_size")
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y) # stratify est important, surtout si non r√©√©quilibr√©
        st.write(f"Taille de l'ensemble d'entra√Ænement : {X_train.shape[0]} √©chantillons")
        st.write(f"Taille de l'ensemble de test : {X_test.shape[0]} √©chantillons")


        st.subheader("Entra√Ænement du Mod√®le Random Forest")
        n_estimators = st.slider("Nombre d'arbres (n_estimators)", 50, 500, 100, 50, key="slider_n_estimators")
        max_depth = st.select_slider("Profondeur maximale (max_depth)", options=[None, 5, 10, 15, 20, 30], value=None, key="slider_max_depth") # None = pas de limite

        with st.spinner("Entra√Ænement du mod√®le en cours..."):
             model = RandomForestClassifier(n_estimators=n_estimators,
                                           max_depth=max_depth,
                                           random_state=42,
                                           n_jobs=-1) # Utiliser tous les c≈ìurs CPU
             model.fit(X_train, y_train)
        st.success("Mod√®le entra√Æn√© avec succ√®s !")


        st.subheader("√âvaluation du Mod√®le")
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        report = classification_report(y_test, y_pred, target_names=encoder_y.classes_) # Utiliser les noms originaux

        st.metric(label="Accuracy sur l'ensemble de test", value=f"{accuracy:.2%}")

        st.text('Rapport de Classification :')
        st.text(report) # Utiliser st.text pour pr√©server le formatage


        st.subheader("Sauvegarder le Mod√®le Entra√Æn√©")
        model_filename = 'model_bank_data.pkl'
        if st.button("Sauvegarder le mod√®le", key="btn_save_model"):
             try:
                with open(model_filename, 'wb') as model_file:
                    # Sauvegarder le mod√®le, l'encodeur de la cible, et les colonnes attendues
                    pickle.dump({
                        'model': model,
                        'encoder_y': encoder_y,
                        'features': data_ready.drop(columns=['y_encoded']).columns.tolist() # Important pour la pr√©diction
                    }, model_file)
                st.success(f"Mod√®le sauvegard√© sous le nom '{model_filename}'")
             except Exception as e:
                st.error(f"Erreur lors de la sauvegarde du mod√®le : {e}")


    elif st.session_state.page_selection == 'prediction':
        st.title("üîÆ Pr√©diction de Souscription Client")

        # Charger le mod√®le et les informations associ√©es
        model_filename = 'model_bank_data.pkl'
        try:
            with open(model_filename, 'rb') as model_file:
                saved_data = pickle.load(model_file)
                model = saved_data['model']
                encoder_y = saved_data['encoder_y']
                expected_features = saved_data['features'] # R√©cup√©rer les noms des features attendues
            st.success(f"Mod√®le '{model_filename}' charg√©.")
        except FileNotFoundError:
            st.error(f"Le fichier mod√®le '{model_filename}' n'a pas √©t√© trouv√©. Veuillez entra√Æner et sauvegarder le mod√®le dans la section 'Apprentissage Automatique'.")
            st.stop()
        except Exception as e:
            st.error(f"Erreur lors du chargement du mod√®le : {e}")
            st.stop()

        st.markdown("Entrez les informations du client pour pr√©dire s'il va souscrire √† un d√©p√¥t √† terme.")

        # Utiliser st.form pour regrouper les champs et le bouton
        with st.form(key='prediction_form'):
            st.subheader("Informations du Client")
            # Utiliser des colonnes pour mieux organiser
            col1, col2, col3 = st.columns(3)

            with col1:
                age = st.number_input("√Çge", min_value=18, max_value=100, value=40, step=1, key="input_age")
                job_options = df_original['job'].unique().tolist() # Utiliser les options du df original
                job = st.selectbox("M√©tier", options=job_options, index=job_options.index('admin.') if 'admin.' in job_options else 0 , key="input_job") # Exemple de valeur par d√©faut
                marital_options = df_original['marital'].unique().tolist()
                marital = st.selectbox("Statut Marital", options=marital_options, index=marital_options.index('married') if 'married' in marital_options else 0, key="input_marital")
                education_options = df_original['education'].unique().tolist()
                education = st.selectbox("Niveau d'√âducation", options=education_options, index=education_options.index('university.degree') if 'university.degree' in education_options else 0, key="input_education")
                default_options = df_original['default'].unique().tolist()
                default = st.selectbox("D√©faut de Cr√©dit ?", options=default_options, index=default_options.index('no') if 'no' in default_options else 0, key="input_default")

            with col2:
                housing_options = df_original['housing'].unique().tolist()
                housing = st.selectbox("Pr√™t Immobilier ?", options=housing_options, index=housing_options.index('yes') if 'yes' in housing_options else 0, key="input_housing")
                loan_options = df_original['loan'].unique().tolist()
                loan = st.selectbox("Pr√™t Personnel ?", options=loan_options, index=loan_options.index('no') if 'no' in loan_options else 0, key="input_loan")
                contact_options = df_original['contact'].unique().tolist()
                contact = st.selectbox("Type de Contact", options=contact_options, index=contact_options.index('cellular') if 'cellular' in contact_options else 0, key="input_contact")
                month_options = df_original['month'].unique().tolist()
                month = st.selectbox("Mois du Dernier Contact", options=month_options, index=month_options.index('may') if 'may' in month_options else 0, key="input_month")
                day_of_week_options = df_original['day_of_week'].unique().tolist()
                day_of_week = st.selectbox("Jour de la Semaine", options=day_of_week_options, index=day_of_week_options.index('thu') if 'thu' in day_of_week_options else 0, key="input_day_of_week")

            with col3:
                 duration = st.number_input("Dur√©e Dernier Contact (secondes)", min_value=0, value=150, step=10, key="input_duration", help="Important: Ce champ influence fortement la pr√©diction mais n'est connu qu'apr√®s l'appel. Pour une pr√©diction r√©aliste *avant* l'appel, il devrait √™tre estim√© ou non utilis√©.")
                 campaign = st.number_input("Nb Contacts Campagne Actuelle", min_value=1, value=2, step=1, key="input_campaign")
                 pdays = st.number_input("Jours Depuis Dernier Contact (Pr√©c. Campagne)", min_value=-1, value=999, step=1, key="input_pdays", help="-1 ou 999 signifie jamais contact√© pr√©c√©demment")
                 previous = st.number_input("Nb Contacts Avant Campagne Actuelle", min_value=0, value=0, step=1, key="input_previous")
                 poutcome_options = df_original['poutcome'].unique().tolist()
                 poutcome = st.selectbox("R√©sultat Pr√©c. Campagne", options=poutcome_options, index=poutcome_options.index('nonexistent') if 'nonexistent' in poutcome_options else 0, key="input_poutcome")

            st.subheader("Indicateurs √âconomiques (valeurs r√©centes typiques)")
            col_eco1, col_eco2, col_eco3 = st.columns(3)
            with col_eco1:
                emp_var_rate = st.number_input("Taux Variation Emploi", value=-0.1, step=0.1, format="%.1f", key="input_emp_var_rate")
            with col_eco2:
                cons_price_idx = st.number_input("Indice Prix Consommation", value=93.2, step=0.1, format="%.1f", key="input_cons_price_idx")
                cons_conf_idx = st.number_input("Indice Confiance Consommateur", value=-42.0, step=0.1, format="%.1f", key="input_cons_conf_idx")
            with col_eco3:
                euribor3m = st.number_input("Taux Euribor 3 Mois", value=1.3, step=0.1, format="%.3f", key="input_euribor3m")
                nr_employed = st.number_input("Nombre d'Employ√©s (milliers)", value=5100.0, step=10.0, format="%.1f", key="input_nr_employed")


            # Bouton pour soumettre le formulaire
            submitted = st.form_submit_button("üîÆ Lancer la Pr√©diction")

            if submitted:
                # Cr√©er un DataFrame avec les entr√©es utilisateur
                input_dict = {
                    'age': age, 'job': job, 'marital': marital, 'education': education, 'default': default,
                    'housing': housing, 'loan': loan, 'contact': contact, 'month': month, 'day_of_week': day_of_week,
                    'duration': duration, 'campaign': campaign, 'pdays': pdays, 'previous': previous, 'poutcome': poutcome,
                    'emp.var.rate': emp_var_rate, 'cons.price.idx': cons_price_idx, 'cons.conf.idx': cons_conf_idx,
                    'euribor3m': euribor3m, 'nr.employed': nr_employed
                }
                input_df = pd.DataFrame([input_dict])

                # --- Appliquer le M√äME pr√©traitement que pour l'entra√Ænement ---
                # 1. G√©rer 'unknown' (ici on suppose que les selectbox n'ont pas 'unknown', sinon il faudrait le g√©rer)
                # Normalement, les selectbox emp√™chent l'entr√©e 'unknown' si elle n'est pas une option valide.

                # 2. Traitement Outliers (si activ√© pendant l'entra√Ænement - important d'√™tre coh√©rent)
                # NOTE : Appliquer le clipping bas√© sur les bornes calcul√©es sur le *train set* serait l'id√©al.
                # Ici, pour simplifier, on suppose que les valeurs entr√©es sont raisonnables ou que le clipping n'√©tait pas critique.
                # Si le clipping √©tait activ√© et important, il faudrait sauvegarder les bornes (lower/upper) pour chaque variable
                # num√©rique et les appliquer ici.

                # 3. Encodage
                # Freq encoding
                for column in categorical_cols_freq: # Utiliser les m√™mes listes que pour l'entra√Ænement
                    # Charger ou recalculer les fr√©quences du jeu d'entra√Ænement est le plus s√ªr
                    # Ici, on recalcule sur df_original pour la d√©mo, MAIS C'EST MOINS ROBUSTE
                    # L'id√©al: Sauvegarder les mappings de fr√©quence avec le mod√®le.
                    fe = df_original.groupby(column).size() / len(df_original)
                    input_df[f'{column}_freq_encode'] = input_df[column].map(fe).fillna(0) # fillna(0) pour les cat√©gories inconnues

                # Label encoding
                le_pred = LabelEncoder() # Recr√©er un encodeur
                for column in categorical_cols_label:
                    # Adapter aux valeurs possibles ('yes', 'no', etc.) comme lors de l'entra√Ænement
                     try:
                        # Il faut s'assurer que l'encodeur est fitt√© sur les m√™mes valeurs que pendant l'entra√Ænement
                        # Le plus simple est de le fitter sur les options possibles du df original
                        le_pred.fit(df_original[column].unique())
                        input_df[column] = le_pred.transform(input_df[column])
                     except Exception as e:
                         st.error(f"Erreur d'encodage pr√©diction pour {column}: {e}. Valeur entr√©e: {input_df[column].iloc[0]}")
                         st.stop()


                # 4. Supprimer les colonnes originales non n√©cessaires
                cols_to_drop_pred = categorical_cols_freq + categorical_cols_label
                input_df_encoded = input_df.drop(columns=cols_to_drop_pred)

                # 5. S'assurer que l'ordre des colonnes est le m√™me que celui attendu par le mod√®le
                try:
                    input_final = input_df_encoded[expected_features] # R√©organiser/s√©lectionner selon l'ordre attendu
                except KeyError as e:
                    st.error(f"Erreur: Colonne manquante ou incorrecte pour la pr√©diction : {e}")
                    st.error(f"Colonnes attendues: {expected_features}")
                    st.error(f"Colonnes apr√®s encodage: {input_df_encoded.columns.tolist()}")
                    st.stop()


                # --- Pr√©diction ---
                prediction_proba = model.predict_proba(input_final)
                prediction = model.predict(input_final)

                probability_yes = prediction_proba[0][1] # Probabilit√© de la classe '1' (yes)
                result_label = encoder_y.inverse_transform(prediction)[0] # Revenir √† 'yes' ou 'no'

                # --- Afficher le r√©sultat ---
                st.subheader("R√©sultat de la Pr√©diction")
                if result_label == 'yes':
                    st.success(f"Le client va probablement souscrire ! (Probabilit√©: {probability_yes:.2%})")
                    st.balloons()
                else:
                    st.warning(f"Le client ne va probablement pas souscrire. (Probabilit√© de souscription: {probability_yes:.2%})")

                # Afficher les probabilit√©s d√©taill√©es
                st.write("Probabilit√©s pr√©dites :")
                st.write(f"- Non ('no'): {prediction_proba[0][0]:.2%}")
                st.write(f"- Oui ('yes'): {prediction_proba[0][1]:.2%}")


# --- Point d'entr√©e de l'application ---
if __name__ == '__main__': # Correction: utiliser __name__ et __main__
    main()
